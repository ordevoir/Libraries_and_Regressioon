{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn <a href=\"https://scikit-learn.org/stable/#\"><img id='logo' height=36 src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\"></a>\n",
    "<style>\n",
    "#logo {\n",
    "    background-color: white;\n",
    "    border-radius: 10px;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn (или sklearn) это библиотека на языке программирования Python, которая используется для решения задач машинного обучения, в том числе классификации, регрессии, кластеризации и обработки данных. Она предоставляет реализацию многих алгоритмов машинного обучения, таких как метод опорных векторов (SVM), случайный лес (Random Forest), метод главных компонент (PCA) и многие другие.\n",
    "\n",
    "Библиотека scikit-learn позволяет быстро создавать и применять модели машинного обучения на больших наборах данных. Она также включает в себя множество функций для предобработки данных, оценки качества моделей и выбора оптимальных параметров моделей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и визуализация данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ice_cream_data = pd.read_csv('ice_cream_selling_train_data.csv')\n",
    "ice_cream_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на тип объекта ice_cream_data\n",
    "type(ice_cream_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ice_cream_data['temperature']\n",
    "y = ice_cream_data['ice_cream_sales']\n",
    "plt.scatter(X, y)\n",
    "plt.ylim(0, 270)\n",
    "plt.xlabel('temperature')\n",
    "plt.ylabel('ice_cream_sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на форму загруженных данных:\n",
    "ice_cream_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи линейной регрессии\n",
    "\n",
    "### Задача регрессии\n",
    "Загруженные данные содержат 40 строк и 2 столбца. Соответственно, в нашем распоряжении 40 образцов с двумя признаками: `temperature` и `ice_cream_sales`. Значения признака `ice_cream_sales` некоторым образом зависит от значений `temperature`. Задача заключается в том, чтобы найти эту закономерность: построить некоторую функцию, которая выражала бы эту зависимость. Это и есть задача регрессии: в общем случае у нас есть целевой числовой признак, который каким-то образом зависит от других признаков, и нужно выяснить, какая функция выражает эту зависимость. В нашем случае у нас есть лишь один нецелевой признак `temperature`, от которого зависит целевой признак `ice_cream_sales`, но чаще целевой признак зависит от многих (нецелевых) признаков."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная зависимость\n",
    "Мы говорим, что целевой признак $y$ зависит **пропорционально** от другого нецелевого признака $x$, если с увеличением значений нецелевого признаков в $k$ раз, целевой признак также увеличивается в $k$ раз, в соответствии с формулой $y=bx$. **Линейная** зависимость выражается формулой $y=a + bx$, т.е. добавляется еще некоторое смещение $a$. В этом случае, если увеличить $x$ на величину $\\Delta x$, то $y$ увеличится на величину, пропорциональную $\\Delta x$:\n",
    "$$\n",
    "\\Delta y = b \\Delta x\n",
    "$$\n",
    "Посмотрим на график. При исходном значении температуры около 14 градусов значения продаж мороженного лежат около 150. Если увеличить температуру на четыре единицы ($\\Delta x = 4$), то при 18 градусах значения продаж мороженного будут лежать около 175, а значит $\\Delta y = 175 - 150 = 25$. Если увеличить температуру на восемь единиц ($\\Delta x = 8$), то при температуре 22 градуса значения целевого признака будутлежать около 200, при этом $\\Delta y = 50$. Обратим внимание на то, что если выбрать $\\Delta x$ вдвое больше, то и $\\Delta y$ будет вдвое больше. Это говорит о том, что в наших данных прослеживается линейная зависимость целевого признака `ice_cream_sales` от нецелевого признака `temperature`.\n",
    "\n",
    "Если по каждому значению $x$ из множества значений признака `temperature` получить значения $y$ по формуле $y = a + bx$, и изобразить эти точки на плоскости, то все точки будут лежать на некоторой прямой (ниже вы сможете в этом убедиться в секции, где нужно будет заменить функцию `plot()` на функцию `scatter()`). Параметры $a$ и $b$ определяют расположение и ориентацию прямой на плоскости. Прямая, которая описывает зависимость в наших данных, должна располагаться на плоскости так, чтобы все точки оказались как можно ближе к ней. \n",
    "\n",
    "Если целевой признак $y$ зависит от нескольких других признаков $x_1, x_2, \\ldots ,x_n$. То формула линейной зависимости будет выглядеть так:\n",
    "$$\n",
    "y = a + b_1 x_1 + b_2 x_2 + \\dots + b_n x_n\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия\n",
    "Целевой признак может зависеть от других признаков довольно сложным образом. Наиболее простым случаем является линейная зависимость. Поэтому, можно начинать с предположения, что целевой признак зависит от других признаков линейным образом, и попробовать решить задачу. И даже если зависимость не является строго линейной, то вполне может быть, что линейное приближение дает приемлемый результат. Оценив результат решения задачи, можно сделать вывод, годится ли такое решение. Если зависимость существенно отличается от линейной, то следует искать нелинейные зависимости."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение данных на обучающую и тестовую выборки\n",
    "\n",
    "Первым делом, нам следует разбить весь набор данных на тренировочную (обучающую) и тестовую выборки. Это необходимо для того, чтобы мы могли проконтролировать правильность работы модели. Ведь может получиться так, что модель хорошо прогнозирует на тех данных, на которых мы ее обучили, и плохо прогнозирует на данных, которые она еще \"не видела\". Поэтому мы целенаправленно отбираем из исходных данных некоторый тестовый набор, который не будет участвовать в обучении. И на этом наборе мы будем проверять, умеет ли модель хорошо прогнозировать целевое значение. Такую проверку еще называют валидацией.\n",
    "\n",
    "Можно самостоятельно написать функцию, которая будет разделять исходные данные на две выборки, но мы воспользуемся функцией `train_test_split()`, которая предоставляется библиотекой `sklearn` в модуле `model_selection`. Первым аргументом в эту функцию передается набор данных, который может быть представлен как объект `DataFrame` или как массив NumPy. Доля данных, которая будет отведена на тестовую выборку указывается в аргументе `test_size`. Обычно достаточно отобрать пятую часть (`0.2`) от всей выборки. Функция `train_test_split()` возвращает кортеж из двух элементов: первый элемент - тренировочная выборка, второй элемент - тестовая выборка. Присвоим эти значения переменным `train_data` и `test_data` соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(ice_cream_data, \n",
    "                                         test_size=0.2,\n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заметим, что отбираются случайные образцы, и производится их перетасовка:\n",
    "test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда данные разбиты на тренировочную и тестовую выборки, преобразуем их в массивы NumPy при помощи метода `to_numpy()`. В `X_train` присвоится массив, содержащий значения признака `temperature`, а в `y_train` - значения целевого признака `ice_cream_sales`, из тренировочного набора. Аналогичным образом, переменным `X_test` и `y_test` присваиваются данные из тестового набора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['temperature'].to_numpy()\n",
    "y_train = train_data['ice_cream_sales'].to_numpy()\n",
    "\n",
    "X_test = test_data['temperature'].to_numpy()\n",
    "y_test = test_data['ice_cream_sales'].to_numpy()\n",
    "\n",
    "# посмотрим на формы массивов:\n",
    "print(f\"{ice_cream_data.shape = }\")\n",
    "print(f\"{X_train.shape = }, {y_train.shape = }\")\n",
    "print(f\"{X_test.shape = }, {y_test.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно признаков много, и `X_train` представляет собой двумерную матрицу, строки которой соответствуют образцам выборки, а столбцы - признакам. Поэтому стандартным представлением выборки является двумерный массив. В нашем случае, так как нецелевой признак у нас единственный, то для `X_train` и `X_test` метод `to_numpy()` вернул одномерные массивы, с формами `(32,)` и `(8,)` соответственно. Поэтому необходимо преобразовать их в привычную форму при помощи метода `reshape()`. Подробнее о том, как работает этот метод смотрите в файле numpy_example.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((32, 1))\n",
    "X_test = X_test.reshape((8, 1))\n",
    "\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь массивы `X_train` и `X_test` являются двумерными массивами, содержащими по одному столбцу. Если признаков будет больше, то такой трансформации формы производить не придется."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор модели и обучение \n",
    "\n",
    "Модель машинного обучения, которую мы будем использовать для решения задачи линейной регрессии реализована в классе `LinearRegression` модуля `linear_model` библиотеки `sklearn`. Данная модель способна решать задачу линейной регрессии. О том, что такое модель, и как именно она это делает, будет написано ниже. А сейчас просто воспользуемся этой моделью дла решения задачи. Первым делом создается объект модели, как экзепляр класса `LinearRegression`. Теперь необходимо обучить модель. Обучение модели производится при помощи метода `fit()`. Первым аргументом модель получает двумерный массив, строки которого соответсвуют образцам тренировочной выборки, а столбцы соответсвтуют признакам, т.е. матрицу с тернировочными данными, содержащими нецелевые признаки. Вторым аргументом передается массив, содержащий значения целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# создается объект модели:\n",
    "model = LinearRegression()       \n",
    "# обучение модели на тренировочных данных:\n",
    "model.fit(X_train, y_train)      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование\n",
    "Теперь, когда модель обучена, она способна прогнозировать целевое значение по заданному нецелевому признаку. Это делается при помощи метода `predict()`, в которой передается один аргумент, содержащий данные с нецелевыми признаками, например, `X_test`. Метод вернет массив содержащий спрогнозированные целевые значения. Присвоим этот массив переменной `y_test_predicted`. Напечатаем в виде таблицы значения, содержащиеся в переменных `X_test`, `y_test` и `y_test_predicted`, чтобы сравнить фактические значения целевого признака и спрогнозированные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получим прогнозы для тестовых данных\n",
    "y_test_predicted = model.predict(X_test)\n",
    "\n",
    "# напечатаем результат в виде таблицы\n",
    "header = f\"X_test\\ty_test\\ty_test_predicted\"\n",
    "print(header, '\\n', '-'*len(header), sep='')\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{X_test[i]}\\t{y_test[i]}\\t{int(y_test_predicted[i])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем прогнозирование также и на тренировочных данных `X_train` и результат присвоим переменной `y_train_predicted`. Нарисуем распределения точек выборки функцией `scatter()`, а для отрисовки точек, соответствующих спрогнозированным значениям, используем функцию `plot()` чтобы получить линию, соединяющую эти точки. Данные тренировочной выборки изображены серыми точками, а данные тестовой выборки - зелеными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# произведем прогнозирование на тренировочных данных\n",
    "y_train_predicted = model.predict(X_train)\n",
    "\n",
    "plt.scatter(X_train, y_train, c='grey', s=15)\n",
    "plt.scatter(X_test, y_test, c='green')\n",
    "plt.plot(X_train, y_train_predicted)\n",
    "plt.ylim(0, 270)\n",
    "\n",
    "plt.xlabel('temperature')\n",
    "plt.ylabel('ice_cream_sales')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линия, соединяющая спрогнозированные значения получилась прямой, как и ожидалось от линейной регрессии. Эта прямая действительно довольно близко расположилась к точкам. Попробуйте использовать функцию `scatter()` вместо `plot()` и непосредственно посмотреть на прогнозные точки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка результата"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы оценить корректность регрессионной модели, можно подсчитать среднеквадратическое отклонение предсказанных значений `y_test_predicted` от фактических значений `y_test`, используя функцию `mean_squared_error()` из модуля `metrics` библиотеки `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "train_rmse = mse(y_train, y_train_predicted, squared=False)\n",
    "test_rmse = mse(y_test, y_test_predicted, squared=False)\n",
    "\n",
    "print(f'{train_rmse = }, {test_rmse = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = f\"X_test\\ty_test\\ty_test_predicted\"\n",
    "print(header, '\\n', '-'*len(header), sep='')\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{X_test[i]}\\t{y_test[i]}\\t{int(y_test_predicted[i])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Среднеквадратическая ошибка**\n",
    "$$\n",
    "\\mathrm{MSE} =  \\frac{1}{n} \\left[(y_1 - \\hat{y_1})^2 + \\dots + (y_n - \\hat{y_n} )^2 \\right]\n",
    "$$\n",
    "В литературе часто встречается такая сокращенная запись:\n",
    "$$\n",
    "\\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y_i} )^2\n",
    "$$\n",
    "где $y_i$ - значения из тестовой выборки, $\\hat y_i$ - значения, спрогнозированные моделью.\n",
    "\n",
    "**Среднеквадратическое отклонение** выражается как корень от среднеквадратической ошибки:\n",
    "$$\n",
    "\\mathrm{RMSE} = \\sqrt{\\mathrm{MSE}}\n",
    "$$\n",
    "Функция `mean_squared_error()` вычисляет среднеквадратическую ошибку (MSE) для двух массивов. Если задать параметр `squared=False`, то функция вычислит среднеквадратическое отклонение (RMSE). Для наглядности, вычислим среднеквадратическую ошибку средствами NumPy, чтобы лучше представить себе, что именно происходит внутри функции `mean_squared_error()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычислми разности между фактическими значениями и прогнозами\n",
    "differences = y_test - y_test_predicted\n",
    "squared_diffs = differences**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напечатаем результаты в виде таблицы для наглядности\n",
    "header = f\"y_test\\ty_test_predicted  differences\\tsquared_diffs\"\n",
    "print(header, '\\n', '-'*len(header), sep='')\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{y_test[i]}\\t{y_test_predicted[i] :.1f}\", end='')\n",
    "    print(f\"\\t\\t  {differences[i] :.4f}\\t{squared_diffs[i] :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = np.mean((y_test - y_test_predicted) ** 2)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение модели\n",
    "В обучающем наборе данных нам для каждой температуры известно было значение продаж. Теперь, когда модель обучена, ее можно использовать для прогнозирования ожидаемого количества продаж мороженного при известной дневной уличной температуре. Значений продаж при этих температурах нам не известно. Модель теперь позволит нам спрогнозировать эти значения.\n",
    "\n",
    "Загрузим данные, содержащие значения температур:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_data = pd.read_csv('ice_cream_sales_temperatures.csv')\n",
    "temperatures_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные, в массив NumPy и спрогнозируем для каждого значения температуры ожидаемое значение продаж мороженного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temperatures_data.to_numpy()\n",
    "y = model.predict(X)\n",
    "y[:5]           # посмотрим прогнозы для первых 5 значений температур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним спрогнозированные значения в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ice_cream_sales_predicts.csv', y, \n",
    "           header='ice_cream_sales', \n",
    "           delimiter=',', \n",
    "           fmt='%.2f', \n",
    "           comments='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что под капотом?\n",
    "### Понятие модели на примере класса `LinearRegression`\n",
    "Моделью в нашем случае называется некоторый объект, который способен получить на \"вход\" нецелевые признаки образца выборки и дать на \"выходе\" целевое значение, которое мы хотим прогнозировать. В рассмотренном выше примере модель представляет собой объект класса `LinearRegression`. На вход она получает единственный признак образца (температуру), на выходе возвращает целевое значение (сколько мороженного ожидается продать при такой температуре). Отвечает за это метод `predict()` (\"*predict*\" означает \"прогнозировать\"). Модель класса `LinearRegression` способна решить задачу линейной регрессии, как можно понять из названия. Для этого необходимо произвести обучение на тренировочных данных. За это отвечает метод `fit()`. Первым аргументом метод получает данные нецелевых признаков образцов выборки, а вторым аргументом получает \"правильные\" ответы (известные значения целевого признака). Часто при этом говорят, что данные \"скармливаются\" модели.\n",
    "\n",
    "Модель в машинном обучении всегда содержит внутри себя параметры, которые подгоняются к оптимальным значениям в процессе обучения (\"*fit*\" означает \"подогнать\"). В результате обучения модели класса `LinearRegression` на одномерных данных, модель создает прямую $f(x) = a + bx$, которая выражает зависимость целевого признака (*target feature*) от единственного (нецелевого) признака. В нашем случае эта прямая должна отражать зависимость продаж мороженного (ice_cream_sales) от уличной температуры (temperature). Параметрами модели являются коэффициенты $a$ и $b$, которые однозначно задают прямую на плоскости признаков."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод наименьших квадратов\n",
    "Метод наименьших квадратов представляет собой алгоритм машинного обучения, который позволяет решать задачу линейной регрессии. В этом методе параметры модели подгоняются так, чтобы среднее значение квадратов разностей $y_i - \\hat y_i$ оказалось минимальным.\n",
    "$$\n",
    "E_2 = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat y_i)^2 = \\frac{1}{n}\\left[(y_1 - \\hat y_1)^2 + \\dots + (y_n - \\hat y_n)^2 \\right]\n",
    "$$\n",
    "Значение $E_2$ характеризует, насколько спрогнозированные значения $\\hat y_i$ далеки от соответсвтующих им фактических значений. Такие функции, характеризующие, насколько один набор значений \"далек\" от другого набора значений, называется метриками. В данном случае имеем дело с L2 метрикой (или метрикой Евклида). \n",
    "\n",
    "В случае одномерной линейной регрессии минимальное значение функции $E_2$ достигается при следующих значениях параметров $a$ и $b$:\n",
    "$$\\hat a = \\overline y - \\hat b \\overline x$$\n",
    "$$\\hat b = \\frac{ \\sum_{i=1}^n (x_i - \\overline x)(y_i - \\overline y)}{\\sum_{i=1}^n (x_i - \\overline x)^2}\n",
    "$$\n",
    "где $ \\overline x$ и  $\\overline y$ - это средние значения.\n",
    "\n",
    "Алгоритм называется методом наименьших квадратов, потому что при оптимальных значениях параметров $\\hat a$ и $\\hat b$ квадраты разностей $y_i - \\hat y_i$ суммарно принимают минимальное из возможных значений.\n",
    "\n",
    "Именно таким образом вычисляются оптимальные параметры модели класса `LinearRegression` при вызове метода `fit()`. Получить коэффициенты $a$ и $b$ из модели можно через свойства `intercept_` и `coef_` соответственно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.intercept_\n",
    "b = model.coef_\n",
    "print(f'{a = }, {b = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При вызове метода `predict()` модель вычисляет прогнозируемое значение для каждого $i$-го образца из `X_test` по формуле $\\hat y_i = a + bx_i$. Убедимся в этом самостоятельно вычислив значения $\\hat y_i$ воспользовавшись полученными из модели параметрами `a` и `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 300 - 9 * X_train\n",
    "\n",
    "y = a + b * X_train\n",
    "# y = model.predict(X_train.reshape(-1, 1))\n",
    "\n",
    "plt.scatter(X_train, y_train, c='grey', s=15)\n",
    "plt.scatter(X_test, y_test, c='green')\n",
    "plt.plot(X_train, y)\n",
    "# plt.plot(X_train, y_train_predicted)\n",
    "plt.ylim(0, 270)\n",
    "plt.xlabel('temperature')\n",
    "plt.ylabel('ice_cream_sales')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика\n",
    "В случае задачи одномерной линейной регрессии \"подогнать параметры к оптимальным значениям\" означает найти такие $a$ и $b$, при которых прямая $f(x) = a + bx$ лучше всего выражает зависимость продаж мороженного от температуры. Но как мы будем определять, какая прямая \"лучше\"? Рассмотрим пару вариантов. Значение температуры произвольной $i$-строки в данных обозначим $x_i$, а соответствующее ему значение продаж мороженного обозначим $y_i$. Когда модель будет прогнозировать значение продаж мороженного по заданному значению температуры $x_i$, результатом будет $\\hat y_i = a + bx_i$. Присмотримся к разности $y_i - \\hat y_i$ (которую в литературе называют невязкой). Если точка оказывается выше прямой, то это значит, что $y_i > \\hat y_i$ и разность будет положительной. Если точка ниже прямой, то разность отрицательная, а если точка лежит на прямой, то разность равна нулю. Что если мы возьмем среднее разностей по всем образцам наших данных и будем считать, что лучшая прямая та, у которой минимальна средняя разность?\n",
    "$$\n",
    "\\frac{1}{n}\\left[(y_1 - \\hat y_1) + \\dots + (y_n - \\hat y_n) \\right]\n",
    "$$\n",
    "Рассмотрим две прямые и соответствующие им средние разности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получим значения на прямой, лежащей вдоль точек:\n",
    "y_along = 70 + 6*X_test.reshape(-1)\n",
    "\n",
    "# получим значения на прямой, лежащая поперек точек\n",
    "# для тестовых данных:\n",
    "y_cross = 350 - 9.2*X_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, c='grey', s = 15)\n",
    "plt.scatter(X_test, y_test, c='green')\n",
    "plt.plot(X_test, y_along, color='blue')\n",
    "plt.plot(X_test, y_cross, color='orange')\n",
    "plt.ylim(0, 260)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полчим разности между значениями `along_diffs` полученными по первой прямой и фактическими значениями `y_test`, полученными из данных. Также получим разности между значениями `cross_diffs` и значениями `y_test`. Результаты отобразим в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_diffs = y_test - y_along\n",
    "cross_diffs = y_test - y_cross\n",
    "\n",
    "header = f\"y_test\\ty_along\\ty_cross\\t along_diffs\\tcross_diffs\"\n",
    "print(header, '\\n', '-'*len(header), sep='')\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{y_test[i]}\\t{y_along[i] :.1f}\\t{y_cross[i] :.1f}\", end='')\n",
    "    print(f\"\\t {along_diffs[i] :.4f} \\t{cross_diffs[i] :.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим средние значения этих разностей `along_diffs` и `cross_diffs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y_along)\n",
    "along_diffs_mean = np.sum(along_diffs) / n\n",
    "cross_diffs_mean = np.sum(cross_diffs) / n\n",
    "\n",
    "print(\"differences mean\")\n",
    "print(f\"blue  : {along_diffs_mean = :.3f}\")\n",
    "print(f\"orange: {cross_diffs_mean = :.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что выбор прямой с минимальной средней разностью будет не лучшим решением, так как это значение у нас оказалось почти одинаковой для двух прямых, хотя очевидно, что синяя прямая описывает распределение точек гораздо лучше оранжевой.\n",
    "\n",
    "Почему так произошло? Взглянем снова на таблицу. Можно обратить внимание, что абсолютные значения в колонке `along_diffs` для разностей по синей прямой, значительно меньше, чем те же значения в колонке `cross_diffs`, соответствующей оранжевой прямой. Но так часть значений в колонках положительные, а часть отрицательные, при суммировании получается почти одинаковый результат, так как положительные значения компенсируют отрицательные и итоговое значение средней разности оказывается близким к нулю. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если бы мы суммировали не сами разности, а их абсолютные значения, то такой компенсации не получилось бы, и оранжевая прямая дала бы большое значение разности. Обозначим среднее от модулей разностей буквой $E_1$\n",
    "$$\n",
    "E_1 = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat y_i| = \\frac{1}{n}\\left(|y_1 - \\hat y_1| + \\dots + |y_n - \\hat y_n| \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_abs_diffs = np.abs(y_test - y_along)\n",
    "cross_abs_diffs = np.abs(y_test - y_cross)\n",
    "\n",
    "n = len(y_along)\n",
    "along_abs_diffs_mean = np.sum(along_abs_diffs) / n\n",
    "cross_abs_diffs_mean = np.sum(cross_abs_diffs) / n\n",
    "\n",
    "print(\"absolute differences means\")\n",
    "print(f\"blue  : {along_abs_diffs_mean = :.3f}\")\n",
    "print(f\"orange: {cross_abs_diffs_mean = :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, c='grey', s = 15)\n",
    "plt.scatter(X_test, y_test, c='green')\n",
    "plt.plot(X_test, y_along, color='blue')\n",
    "plt.plot(X_test, y_cross, color='orange')\n",
    "plt.ylim(0, 260)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальное значение функции $E_1$ достигается для зеленой прямой. В идеальном случае все точки лежали бы на прямой, и функция $E_1$ приняла бы значение 0. Это минимальное допустимое значение, так как сумма неотрицательных чисел не может быть отрицательной. Чем больше точек отклоняются от прогнозируемых значений и чем сильнее они отклоняются, тем больше будет $E_1$. Поэтому можно сказать, что функция $E_1$ характеризует ошибочность модели на данных. Чем меньше будет $E_1$, тем меньше ее ошибочность, и, соответственно, лучше результаты. Такие функции называются **метриками**, а в частности рассмотренная функция $E_1$ называется метрикой L1 (или метрикой городских кварталов)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Если признаков много\n",
    "В рассмотренном примере всего один нецелевой признак, поэтому решалась задача одномерной регрессии. Как упоминалось выше, признаков $x_1, x_2, \\ldots, x_n$, от которых зависит целевой признак $y$ может быть несколько. Тогда мы имеем дело с многомерной регрессией. Если модели класса `LinearRegression` \"скормить\" данные, содержащие $n$ признаков, то она создаст внутри себя параметры $a, b_1, b_2, \\ldots, b_n$ и подгонит их так, чтобы формула \n",
    "$$\n",
    "y = a + b_1 x_1 + b_2 x_2 + \\dots + b_n x_n\n",
    "$$\n",
    "выражала зависимость целевого признака $y$ от других признаков $x_1, x_2, \\ldots, x_n$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
